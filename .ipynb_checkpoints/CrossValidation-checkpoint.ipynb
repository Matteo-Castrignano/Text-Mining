{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Number of tweets: 1021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vaccini: il successo della brexit premetterã  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aifa autorizza il vaccino astrazeneca ma ne ra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vaccini mentre l'eu cerca (tra l'altro senza s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>si andrebbe presumibilmente ben oltre l'anno. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oggi 30 gennaio , ho ricevuto la seconda dose ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>the_huge_ giusepperisso vivianabillo se una pe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>covid-19: la cina approva il suo primo vaccino...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>ponytaele ladyonorato che senso avrebbe questa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>coolo_fun lilianaarmato chetempochefa lei si v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>anticorpi monoclonali per 'accompagnare' il va...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  label\n",
       "0     vaccini: il successo della brexit premetterã  ...      1\n",
       "1     aifa autorizza il vaccino astrazeneca ma ne ra...      1\n",
       "2     vaccini mentre l'eu cerca (tra l'altro senza s...      0\n",
       "3     si andrebbe presumibilmente ben oltre l'anno. ...      2\n",
       "4     oggi 30 gennaio , ho ricevuto la seconda dose ...      1\n",
       "...                                                 ...    ...\n",
       "1016  the_huge_ giusepperisso vivianabillo se una pe...      2\n",
       "1017  covid-19: la cina approva il suo primo vaccino...      2\n",
       "1018  ponytaele ladyonorato che senso avrebbe questa...      2\n",
       "1019  coolo_fun lilianaarmato chetempochefa lei si v...      1\n",
       "1020  anticorpi monoclonali per 'accompagnare' il va...      2\n",
       "\n",
       "[1021 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "pandas.set_option('display.max_rows', 1000)\n",
    "\n",
    "# loading the dataset\n",
    "dataset = pandas.read_csv(\"training_set.csv\",sep=',',usecols=['tweet','label'])\n",
    "\n",
    "print(type(dataset))\n",
    "print(f\"Number of tweets: {len(dataset)}\")\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "italian_stemmer = SnowballStemmer('italian')\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([italian_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy MultinomialNB : 0.50 (+/- 0.15)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIMPLE PIPELINE WITHOUT ANY TEST ON ngram_range AND CONSIDERING ONLY ACCURACY AS METRIC\n",
    "# SE GLI ALTRI TEST VANNO BENE QUESTO SI PUO' ANCHE ELIMINARE\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', StemmedCountVectorizer(min_df=2, analyzer=\"word\", stop_words = set(stopwords.words('italian')),ngram_range = (1,1))),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "folds =  10\n",
    "#calculating accuracies in cross-validation\n",
    "scores = cross_val_score(text_clf, dataset.tweet, dataset.label, cv=folds)\n",
    "(\"Accuracy MultinomialNB : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "#print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score, average = 'weighted', zero_division = 0),\n",
    "           'recall' : make_scorer(recall_score, average = 'macro'), \n",
    "           'f1_score' : make_scorer(f1_score, average = 'macro')\n",
    "          }\n",
    "\n",
    "def print_metrics(scores):\n",
    "    print(f'accuracy on test set: {scores[\"test_accuracy\"].mean():.3} +/- {scores[\"test_accuracy\"].std()*2:.3}')\n",
    "    print(f'precision on test set: {scores[\"test_precision\"].mean():.3} +/- {scores[\"test_precision\"].std()*2:.3}')\n",
    "    print(f'recall on test set: {scores[\"test_recall\"].mean():.3} +/- {scores[\"test_recall\"].std()*2:.3}')\n",
    "    print(f'f1-score on test set: {scores[\"test_f1_score\"].mean():.3} +/- {scores[\"test_f1_score\"].std()*2:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES CLASSIFIER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ngram = (1, 1) -------\n",
      "accuracy on test set: 0.496 +/- 0.147\n",
      "precision on test set: 0.494 +/- 0.145\n",
      "recall on test set: 0.484 +/- 0.169\n",
      "f1-score on test set: 0.481 +/- 0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ngram = (1, 2) -------\n",
      "accuracy on test set: 0.501 +/- 0.131\n",
      "precision on test set: 0.499 +/- 0.129\n",
      "recall on test set: 0.489 +/- 0.158\n",
      "f1-score on test set: 0.487 +/- 0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ngram = (2, 2) -------\n",
      "accuracy on test set: 0.425 +/- 0.115\n",
      "precision on test set: 0.429 +/- 0.119\n",
      "recall on test set: 0.414 +/- 0.121\n",
      "f1-score on test set: 0.413 +/- 0.121\n"
     ]
    }
   ],
   "source": [
    "max_ngram = 2\n",
    "\n",
    "print('NAIVE BAYES CLASSIFIER')\n",
    "for i in range(max_ngram):\n",
    "    for j in range(max_ngram):\n",
    "        if j>= i :\n",
    "            text_clf = Pipeline([\n",
    "                ('vect', StemmedCountVectorizer(min_df=2, analyzer=\"word\", stop_words = set(stopwords.words('italian')),ngram_range = (i+1,j+1))),\n",
    "                ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "                ('clf', MultinomialNB()),\n",
    "            ])\n",
    "            scores = cross_validate(text_clf, dataset.tweet, dataset.label, cv=folds, scoring = scoring)\n",
    "            print(f\"------- ngram = {(i+1,j+1)} -------\")\n",
    "            print_metrics(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE CLASSIFIER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ngram = (1, 1) -------\n",
      "accuracy on test set: 0.41 +/- 0.148\n",
      "precision on test set: 0.407 +/- 0.155\n",
      "recall on test set: 0.393 +/- 0.188\n",
      "f1-score on test set: 0.389 +/- 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ngram = (1, 2) -------\n",
      "accuracy on test set: 0.401 +/- 0.0851\n",
      "precision on test set: 0.399 +/- 0.0887\n",
      "recall on test set: 0.39 +/- 0.101\n",
      "f1-score on test set: 0.386 +/- 0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ngram = (2, 2) -------\n",
      "accuracy on test set: 0.372 +/- 0.0928\n",
      "precision on test set: 0.378 +/- 0.0957\n",
      "recall on test set: 0.362 +/- 0.0853\n",
      "f1-score on test set: 0.356 +/- 0.0844\n"
     ]
    }
   ],
   "source": [
    "print('DECISION TREE CLASSIFIER')\n",
    "for i in range(max_ngram):\n",
    "    for j in range(max_ngram):\n",
    "        if j>= i :\n",
    "            text_clf = Pipeline([\n",
    "                ('vect', StemmedCountVectorizer(min_df=2, analyzer=\"word\", stop_words = set(stopwords.words('italian')),ngram_range = (i+1,j+1))),\n",
    "                ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "                ('clf', tree.DecisionTreeClassifier()),\n",
    "            ])\n",
    "            scores = cross_validate(text_clf, dataset.tweet, dataset.label, cv=folds, scoring = scoring)\n",
    "            print(f\"------- ngram = {(i+1,j+1)} -------\")\n",
    "            print_metrics(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CLASSIFIER\n",
      "------- ngram = (1, 1) -------\n",
      "accuracy on test set: 0.493 +/- 0.156\n",
      "precision on test set: 0.491 +/- 0.159\n",
      "recall on test set: 0.491 +/- 0.16\n",
      "f1-score on test set: 0.488 +/- 0.159\n",
      "------- ngram = (1, 2) -------\n",
      "accuracy on test set: 0.517 +/- 0.181\n",
      "precision on test set: 0.516 +/- 0.181\n",
      "recall on test set: 0.514 +/- 0.18\n",
      "f1-score on test set: 0.511 +/- 0.18\n",
      "------- ngram = (2, 2) -------\n",
      "accuracy on test set: 0.398 +/- 0.139\n",
      "precision on test set: 0.401 +/- 0.167\n",
      "recall on test set: 0.389 +/- 0.133\n",
      "f1-score on test set: 0.383 +/- 0.132\n"
     ]
    }
   ],
   "source": [
    "print('SVM CLASSIFIER')\n",
    "for i in range(max_ngram):\n",
    "    for j in range(max_ngram):\n",
    "        if j>= i :\n",
    "            text_clf = Pipeline([\n",
    "                ('vect', StemmedCountVectorizer(min_df=2, analyzer=\"word\", stop_words = set(stopwords.words('italian')),ngram_range = (i+1,j+1))),\n",
    "                ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "                ('clf', svm.LinearSVC()),\n",
    "            ])\n",
    "            scores = cross_validate(text_clf, dataset.tweet, dataset.label, cv=folds, scoring=scoring)\n",
    "            print(f\"------- ngram = {(i+1,j+1)} -------\")\n",
    "            print_metrics(scores)\n",
    "            #print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def overall_average_score(actual,prediction):\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(\n",
    "        actual, prediction, average=None)\n",
    "    print(type(f1_score))\n",
    "    return f1_score.mean()\n",
    "\n",
    "custom_scorer = make_scorer(overall_average_score)\n",
    "\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', StemmedCountVectorizer(min_df=2, analyzer=\"word\", stop_words = set(stopwords.words('italian')),ngram_range = (1,1))),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "scores = cross_val_score(text_clf, dataset.tweet, dataset.label, cv=folds, scoring = custom_scorer)\n",
    "print(scores) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
