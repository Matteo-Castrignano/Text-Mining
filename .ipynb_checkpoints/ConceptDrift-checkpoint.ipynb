{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(date_text):\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Incorrect data format, should be YYYY-MM-DD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_stemmer = SnowballStemmer('italian')\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([italian_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweet_Period(df, start_date = \"2021-02-01\", end_date = \"2021-05-31\"):\n",
    "    \n",
    "    validate(start_date)\n",
    "    validate(end_date)\n",
    "    \n",
    "    return test_set[(test_set['timestamp'] > start_date) & (test_set['timestamp'] < end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1365805791391985671</td>\n",
       "      <td>2021-02-28 00:27:30</td>\n",
       "      <td>filipporiccio1</td>\n",
       "      <td>l hanno gia data questa disponibilita moderna...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1365801638821306375</td>\n",
       "      <td>2021-02-28 00:11:00</td>\n",
       "      <td>cavinadenise</td>\n",
       "      <td>in molti che non sanno che non c era ancora u...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1365797552323518465</td>\n",
       "      <td>2021-02-27 23:54:46</td>\n",
       "      <td>biber0n1</td>\n",
       "      <td>il vaccino deve essere un farmaco generico pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1365794542172180481</td>\n",
       "      <td>2021-02-27 23:42:48</td>\n",
       "      <td>icolomboa</td>\n",
       "      <td>due mesi fa di questi giorni tra tanto scettic...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1365792763552428034</td>\n",
       "      <td>2021-02-27 23:35:44</td>\n",
       "      <td>attilaazurerive</td>\n",
       "      <td>tanta voglia di iri e di ritorno ai vecchi dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35291</th>\n",
       "      <td>1388313650797101057</td>\n",
       "      <td>2021-05-01 04:05:42</td>\n",
       "      <td>yy01329</td>\n",
       "      <td>il boom dei vaccini raggiunta quota 500 mila a...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35292</th>\n",
       "      <td>1388309589121187843</td>\n",
       "      <td>2021-05-01 03:49:34</td>\n",
       "      <td>claudiomarang1</td>\n",
       "      <td>del vaccino cubano ben che vada vedremo la lu...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35293</th>\n",
       "      <td>1388299190426644489</td>\n",
       "      <td>2021-05-01 03:08:15</td>\n",
       "      <td>bludichina</td>\n",
       "      <td>e il target primario dei vaccini attenuare i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35294</th>\n",
       "      <td>1388283826883944455</td>\n",
       "      <td>2021-05-01 02:07:12</td>\n",
       "      <td>ery975</td>\n",
       "      <td>canzone bella ma con una pecca nomina astraze...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35295</th>\n",
       "      <td>1388282015645065219</td>\n",
       "      <td>2021-05-01 02:00:00</td>\n",
       "      <td>infoitinterno</td>\n",
       "      <td>quali fattori scatenano le trombosi cosa saper...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33532 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id            timestamp         username  \\\n",
       "0      1365805791391985671  2021-02-28 00:27:30   filipporiccio1   \n",
       "1      1365801638821306375  2021-02-28 00:11:00     cavinadenise   \n",
       "2      1365797552323518465  2021-02-27 23:54:46         biber0n1   \n",
       "3      1365794542172180481  2021-02-27 23:42:48        icolomboa   \n",
       "4      1365792763552428034  2021-02-27 23:35:44  attilaazurerive   \n",
       "...                    ...                  ...              ...   \n",
       "35291  1388313650797101057  2021-05-01 04:05:42          yy01329   \n",
       "35292  1388309589121187843  2021-05-01 03:49:34   claudiomarang1   \n",
       "35293  1388299190426644489  2021-05-01 03:08:15       bludichina   \n",
       "35294  1388283826883944455  2021-05-01 02:07:12           ery975   \n",
       "35295  1388282015645065219  2021-05-01 02:00:00    infoitinterno   \n",
       "\n",
       "                                                   tweet  likes_count  label  \n",
       "0       l hanno gia data questa disponibilita moderna...            4    NaN  \n",
       "1       in molti che non sanno che non c era ancora u...            0    NaN  \n",
       "2       il vaccino deve essere un farmaco generico pr...            1    NaN  \n",
       "3      due mesi fa di questi giorni tra tanto scettic...            0    NaN  \n",
       "4      tanta voglia di iri e di ritorno ai vecchi dis...            0    NaN  \n",
       "...                                                  ...          ...    ...  \n",
       "35291  il boom dei vaccini raggiunta quota 500 mila a...            2    NaN  \n",
       "35292   del vaccino cubano ben che vada vedremo la lu...            1    NaN  \n",
       "35293   e il target primario dei vaccini attenuare i ...            0    NaN  \n",
       "35294   canzone bella ma con una pecca nomina astraze...            1    NaN  \n",
       "35295  quali fattori scatenano le trombosi cosa saper...            0    NaN  \n",
       "\n",
       "[33532 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data and a short phase of preprocess\n",
    "test_set = pd.read_csv(\"test_set.csv\",sep=',')\n",
    "test_set.drop_duplicates(subset=['tweet'])\n",
    "#testset\n",
    "#print(f\"Number of tweets: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('AccountToDelete.txt') as f:\n",
    "    for line in f:\n",
    "        news.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = test_set[ test_set['username'].isin(news)].index\n",
    "test_set.drop(indexNames, inplace=True)\n",
    "#print(f\"Number of tweets: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.sort_values(by=['likes_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = search_tweet_Period(test_set, \"2021-02-01\", \"2021-02-28\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"ConceptDriftFebbraio.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do classification by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload data\n",
    "data = pd.read_csv(\"ConceptDrift-NomeMese-\",sep=',',names=['tweet','label'])\n",
    "training_set = pd.read_csv(\"training_set.csv\",sep=',',names=['tweet','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the all the data\n",
    "new_trainin_set = pd.concat(training_set,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "clf = Pipeline([\n",
    "    ('vect', StemmedCountVectorizer(min_df=3, analyzer=\"word\", stop_words = set(stopwords.words('italian')), ngram_range = (1,1))),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "    ('clf',BernoulliNB()),\n",
    "])\n",
    "clf.fit(new_trainin_set.tweet, new_trainin_set.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the new model\n",
    "joblib.dump(clf, 'model-NomeMese-.pkl', compress=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
