{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training-set\n",
    "training_set = pd.read_csv(\"training_set.csv\",sep=',',names=['tweet','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the classifier\n",
    "clf = Pipeline([\n",
    "    ('vect', StemmedCountVectorizer(min_df=3, analyzer=\"word\", stop_words = set(stopwords.words('italian')), ngram_range = (1,1))),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "    ('clf',BernoulliNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 StemmedCountVectorizer(min_df=3,\n",
       "                                        stop_words={'a', 'abbia', 'abbiamo',\n",
       "                                                    'abbiano', 'abbiate', 'ad',\n",
       "                                                    'agl', 'agli', 'ai', 'al',\n",
       "                                                    'all', 'alla', 'alle',\n",
       "                                                    'allo', 'anche', 'avemmo',\n",
       "                                                    'avendo', 'avesse',\n",
       "                                                    'avessero', 'avessi',\n",
       "                                                    'avessimo', 'aveste',\n",
       "                                                    'avesti', 'avete', 'aveva',\n",
       "                                                    'avevamo', 'avevano',\n",
       "                                                    'avevate', 'avevi', 'avevo', ...})),\n",
       "                ('tfidf', TfidfTransformer()), ('clf', BernoulliNB())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the classifier\n",
    "clf.fit(training_set.tweet, training_set.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InitialModel88888.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the model\n",
    "joblib.dump(clf, 'InitialModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
